{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "896e8f826041432b4abc0c4904b4f5751f47c410ed75a08b06783af40a876905"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May have to remove / comment out if training info not present\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Importing\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "from datetime import datetime \n",
    "\n",
    "# PROCESSING\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical # np utils\n",
    "\n",
    "# MODEL\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, SpatialDropout2D, PReLU, LeakyReLU, BatchNormalization\n",
    "from keras.layers import Convolution2D, Conv2D, GlobalAveragePooling2D, MaxPooling2D, SpatialDropout2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "# TRAINING\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "\n",
    "print(\"Finished Importing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1        \n",
    "\n",
    "# Extract Features\n",
    "def extract_features(file_name):\n",
    "    max_pad_len = 174\n",
    "    try:\n",
    "        # Loading audio file\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        # Extracting MFCCs\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "\n",
    "        print(mfccs.shape)\n",
    "        # If we have to many features, cut them, not needed\n",
    "        if (mfccs.shape[1] <= max_pad_len):\n",
    "            pad_width = max_pad_len - mfccs.shape[1]\n",
    "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else: # Limit the number of features we use to 174\n",
    "            mfccs = mfccs[:,:174]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error parsing: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs\n",
    "\n",
    "def print_prediction(file_name, model):\n",
    "    features = extract_features(file_name) \n",
    "    features = features.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict_classes(features)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"Predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    proba_vector = model.predict(features) \n",
    "    predicted_proba = proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "model_test = load_model('saved_models/new_model_4_class')\n",
    "\n",
    "\n",
    "\n",
    "#score = model_test.evaluate(x_test, y_test, verbose=0)\n",
    "#print(\"Verified Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(40, 317)\n",
      "C:\\Users\\Devin\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "Predicted class is: noise \n",
      "\n",
      "car_horn \t\t :  0.00000000000137141838683907391072\n",
      "construction \t\t :  0.02717502601444721221923828125000\n",
      "noise \t\t :  0.97282481193542480468750000000000\n",
      "siren \t\t :  0.00000006482983394562324974685907\n"
     ]
    }
   ],
   "source": [
    "model_test = load_model('saved_models/new_model_4_class')\n",
    "\n",
    "\n",
    "filename = 'audio/drums.wav'\n",
    "\n",
    "print_prediction(filename, model_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}