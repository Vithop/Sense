{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tf-gpu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "03fb704c3b4e7767d196c93df1c266a39bde6bf56fa13ddd2e03c527af316e51"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May have to remove / comment out if training info not present\n",
    "%store -r x_train \n",
    "%store -r x_test \n",
    "%store -r y_train \n",
    "%store -r y_test \n",
    "%store -r yy \n",
    "%store -r le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished Importing\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "from datetime import datetime \n",
    "\n",
    "# PROCESSING\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# MODEL\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical # np utils\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, SpatialDropout2D, PReLU, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.layers import Convolution2D, Conv2D, GlobalAveragePooling2D, MaxPooling2D, SpatialDropout2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "# TRAINING\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "\n",
    "print(\"Finished Importing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1        \n",
    "\n",
    "# Extract Features\n",
    "def extract_features(file_name):\n",
    "    max_pad_len = 174\n",
    "    try:\n",
    "        # Loading audio file\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        # Extracting MFCCs\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "\n",
    "        print(mfccs.shape)\n",
    "        # If we have to many features, cut them, not needed\n",
    "        if (mfccs.shape[1] <= max_pad_len):\n",
    "            pad_width = max_pad_len - mfccs.shape[1]\n",
    "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else: # Limit the number of features we use to 174\n",
    "            mfccs = mfccs[:,:174]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error parsing: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs\n",
    "\n",
    "def print_prediction(file_name, model):\n",
    "    features = extract_features(file_name) \n",
    "    features = features.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict_classes(features)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"Predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    proba_vector = model.predict(features) \n",
    "    predicted_proba = proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "model_test = load_model('saved_models/new_model_4_class')\n",
    "\n",
    "\n",
    "\n",
    "#score = model_test.evaluate(x_test, y_test, verbose=0)\n",
    "#print(\"Verified Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(40, 317)\n",
      "/home/vithuran/anaconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'le' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0bd1fa84206d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'audio/drums.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-60f154d7c69f>\u001b[0m in \u001b[0;36mprint_prediction\u001b[0;34m(file_name, model)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpredicted_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted class is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'le' is not defined"
     ]
    }
   ],
   "source": [
    "model_test = load_model('saved_models/new_model_4_class')\n",
    "\n",
    "\n",
    "filename = 'audio/drums.wav'\n",
    "\n",
    "print_prediction(filename, model_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}